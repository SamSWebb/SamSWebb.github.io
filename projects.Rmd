---
title: "Projects"
---

Here you can find my current projects, where I am leading author, all are open access, or otherwise stated. Hyperlinks take you direct to pre-prints, publications, and data repositories.

![](Project%20collage.png){width="100%"} 

## <span style="color:black">**Pending publications**

### <span style="color:grey90">Stroke Recovery During the COVID-19 Pandemic: A Position Paper on Recommendations for Rehabilitation

Health care delivery shifted and adapted with the coronavirus disease 2019 (COVID-19) pandemic caused by the novel severe acute respiratory syndrome (SARS) coronavirus 2 (CoV-2). Stroke care has been negatively impacted across the care continuum and may be leading to poor community living outcomes in those who have survived a stroke during the ongoing pandemic. It is expected that the fallout from the pandemic will be great and may be particularly felt among people surviving stroke during this unprecedented time. The American Congress of Rehabilitation Medicine (ACRM) Stroke Interdisciplinary Special Interest Group (Stroke ISIG) Health and Wellness Task Force convened to (1) discuss international experiences in stroke care and rehabilitation and (2) review recently published literature on stroke care and outcomes during the pandemic. Based on the findings in the literature, the task force proposes recommendations and interdisciplinary approaches in health care delivery spanning across the care continuum and into the community to support and enhance stroke recovery outcomes during the pandemic.

- Status: under review

## <span style="color:black">**Stage 1 Accepted Registered Reports:**

### <span style="color:grey90">[Pre-Attentive Processing in Visuospatial Neglect: Burning Houses Revisited](https://osf.io/5trcx/)

-   The project seeks to replicate the pre-attentive semantic processing effect first documented by [Marshall and Halligan (1988)](https://www.nature.com/articles/336766a0) under more stringent experimental conditions, and in a broad, representative sample while investigating whether semantic or merely physical stimuli differences are responsible for modulating the occurrence of pre-attentive processing in neglect patients.

## <span style="color:black">**Preprints:**

### <span style="color:grey90">[Multiverse Analysis: A Method to Determine Researcher Degrees of Freedom in Test Validation](https://osf.io/cktj9/)

In psychometric validation there are a near limitless number of different approaches researchers can decide to take when choosing sample type and size, test metrics, and covariate measures. It is particularly important to factor in these different analytical pathways when validating tools intended for use in clinical populations. Here, we aimed to provide a tutorial paper showcasing the multiverse, or specification curve, technique to establish the robustness of analytical pathways on psychometric validation outcomes in an example test of executive function. We examined the impact of choices regarding sample groups, sample sizes, different types of metrics from a given test, covariate inclusions, and outlier removal on convergent validation correlations between new tests of executive function. Data were available for 88 neurologically healthy adults and 117 stroke survivors, a total of 6,660 different analyses were run. We found that the type of sample group and sample size used for analyses impacted validation outcomes. Comparing test metrics within-category (e.g.accuracy vs accuracy) rather than between-category (e.g., accuracy vs time) significantly increased the observed correlation coefficients. Covariate inclusion and outlier removal choices did not impact the observed coefficients in our analyses. This tutorial paper showcases how authors can use the multiverse technique to evidence the robustness, or fragility, of their validation outcomes across many different analytical pathways. The example here highlights the importance of fully justifying and considering the analytical pathway to take in validation work on clinically relevant tools.

-   Pre-print available on [PsyArxiv](https://psyarxiv.com/nhrwq/)

- Status: under revision


## <span style="color:black">**Ongoing Projects 2021-:**

### <span style="color:grey90">Ecological and predictive validity of the Oxford Digital Multiple Errands Test (OxMET) in stroke ##

The Oxford Digital Multiple Errands Test (OxMET) is a brief cognitive screen, intended as an ecologically valid approach to assessing complex executive function, in contrast to traditional abstract neuropsychological assessments with high language demands. Initial psychometric validation of the OxMET found high internal reliability and test-retest reliability, as well as good convergent and divergent validity. Here we assess aspects of predictive and ecological validity of the OxMET measures in relation to commonly used clinical function scales in a subacute stroke sample.
Participants within 3 months of confirmed stroke were recruited from a UK English-speaking specialist stroke rehabilitation in-patient setting between 2020 and 2022. Each completed the OxMET with a researcher, whilst clinical outcome measures were collected from medical notes: Barthel Index and stroke the specific Therapy Outcome Measure scale.
As of March 2022: Participants (n=333) were on average 24.94 days post stroke (SD=16.46), had a mean age of 73.8 (SD =13.05) and mean NIH Stroke Severity of 8.24 (SD= 5.32). We followed up a subset of 48 participants to complete activities of daily living and cognitive failures questionnaires to compare to baseline OxMET performance.
At baseline we found a significant but small relationship between the OxMET accuracy Barthel Index (r=.22) but we did not find a relationship between functioning and more specialist OxMET metrics such as error types. At 6-month follow we found a moderate relationship between the OxMET accuracy metric and activities of daily living (R2=.31)
The OxMET, an executive function assessment screen, was found to associate to specialist stroke relevant measures of functionality both in a rehabilitation context and community setting, but not beyond accuracy on the task. We note that the measures have a strong physical focus which may limit associations. The OxMET could be a useful and ecologically relevant tool in assessing executive function in those with limited physical or language abilities.

-   Status: Under active recruitment

### <span style="color:grey90">Validation of the Oxford Cognitive Screen-Plus in UK-based English-speaking subacute and chronic stroke survivor cohorts

Stroke survivors are routinely screened for cognitive impairment with screening tools which often fail to detect subtle impairments. The Oxford Cognitive Screen â€“ Plus (OCS-Plus) is a brief computer tablet-based screening tool designed to detect more subtle impairments. We aimed to examine its psychometric properties in two stroke cohorts (subacute = <3 months post-stroke and chronic = 6 months post-stroke).
As of March 2022: 338 stroke survivors (172 subacute, 166 chronic, average age 73 (SD=13), education 13 (SD=3), sex 42.73% female presenting, ~3.42% ischaemic stroke), from two in-patient stroke units in the UK were recruited between May 2016 and March 2022, and a subset was followed up at 6-months post-stroke. All participants completed the OCS and OCS-Plus. A subset additionally completed the Montreal Cognitive Assessment (MoCA), and further format- and construct-matched neuropsychological tests. Due to the tablet-based format, OCS-Plus provides standardised assessment for non-specialist administration and automatic real time impairment classification against a matched normative set.
Construct validity criteria were met and exceeded the psychometric findings in the original psychometric validation using healthy control data. Incidence of cognitive impairment was higher in subacute stroke survivors compared to chronic stroke survivors, with the highest rates of impairment found for visuospatial and executive subtests. We report the sensitivity and specificity of each OCS-Plus subtest compared to neuropsychological test performance. Notably, many of those who were unimpaired on the MoCA and Oxford Cognitive Screen, demonstrated impairment on neuropsychological testing and OCS-Plus screening.
The OCS-Plus is a valid cognitive screening tool for use in stroke. OCS-Plus is able to detect subtle cognitive impairment at a similar level to selected neuropsychological assessments and exceeds detection of impairment compared to the OCS and MoCA.

-   Status: Under active recruitment

### <span style="color:grey90">[The Oxford COMPetency ASSessment(COMPASS): A Brief Supplemental Cognitive Assessment Aligned with Mental Capacity Criteria](http://www.demeyerelab.org/?page_id=469)

Assessment of mental capacity is a critical aspect of clinical practice. Mental capacity is a legal concept defined in statute by the Mental Capacity Act 2005 (England and Wales). Current best practice consists of a qualitative interview to elucidate the ability to (i) understand, (ii) retain and (iii) weigh up the specific information at hand, and to (iv) communicate a decision. Capacity assessments often fail to align with the legal standards and are often contentious with low agreement rates. We developed and validated a new brief neuropsychological screening tool (The Oxford Competency Assessment; COMPASS) to assess the cognitive constructs aligned to the core abilities required for mental capacity. 
122 neurologically healthy participants were compared with 117 participants with neurological conditions (stroke or dementia/mild cognitive impairment) on COMPASS performance. The validation included 56 control participants and 69 neurological participants who completed additional neuropsychological tasks including the MoCA. 29 participants were re-tested. 80 participants were compared against a mental capacity assessment on setting up a hypothetical Lasting Power of Attorney.
We found great reliability of the COMPASS, convergent validity analysis revealed low but significant correlations, and divergent validation was achieved. The COMPASS total score was similar to the MoCA in identifying impairment in mental capacity assessments, but neither were adequate to differentiate impairment in core abilities (i.e., understanding, retention, or weighing up)
Further research comparing the COMPASS to capacity assessments with differing complexity is necessary, and to see whether the COMPASS increases interrater reliability in capacity assessments.
- Status: In preparation


## <span style="color:black">**Unpublished / Unpre-printed works**

### [MSc Dissertation](https://osf.io/cktj9/)

-   This forms the storage for my MSc work

-   Including

    -   Final anonymised data (both controls and patients data)
    -   Analysis script to reproduce my analysis
    -   Original pre-registration and files explaining changes along the research pipeline

### [Essay on alternative facts in psychology](https://osf.io/5wmkr/)

-   This was an essay I wrote in 2017 for my second year of my undergraduate when I just got into Open science. I uploaded this more as a personal joke as I had no idea about open science at that point and had only just stumbled into the state of psychology (i.e., it is on fire).

